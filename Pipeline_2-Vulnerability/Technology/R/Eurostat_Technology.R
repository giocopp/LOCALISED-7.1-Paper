# Set working directory
setwd("/Users/giocopp/Desktop/LOCALISED-7.1-Paper/Pipeline_2-Vulnerability/Technology")

### Install Necessary Packages ###
remotes::install_github("eurostat/restatapi")

libs <- c(
  "restatapi",
  "tidyverse",
  "giscoR",
  "sf",
  "classInt",
  "mice",
  "visdat",
  "VIM"
)

installed_libs <- libs %in% rownames(
  installed.packages()
)

if (any(installed_libs == FALSE)) {
  install.packages(
    libs[!installed_libs],
    dependencies = TRUE
  )
}

invisible(
  lapply(
    libs, library,
    character.only = TRUE
  )
)

### GET DATA
### 
### RIS data

# RIS <- readxl::read_excel("/Users/giocopp/Desktop/LOCALISED-7.1-Paper/Base Data/RIS_2023.xlsx") |>
#   dplyr::filter(Year == 2023) |>
#   mutate(Indicator_ID = str_extract(Indicator, "^[0-9.]+")) |>
#   select(Indicator_ID, everything())
# 
# RIS <- RIS |>
#   filter(!Indicator_ID %in% c("0", "1.1.1", "1.1.2", "1.1.3", "2.3.1", "2.3.2", "3.2.2", "3.2.3",
#                               "4.3.1", "4.3.2", "1.1", "4.1", "4.2", "5.1.3", "5.1.5", "5.1.8",
#                               "5.1.9", "5.2.2", "5.4.2", "5.4.4", "5.5.2", "5.6.1", "5.6.2", "5.6.3"))
# 
# base_data <- readxl::read_excel("/Users/giocopp/Desktop/LOCALISED-7.1-Paper/Base Data/base_data_plus.xlsx")
# 
# RIS <- base_data |>
#   left_join(RIS, by = c("RIS_code" = "Region")) |>
#   filter(nchar(NUTS_ID) != 2) |>
#   rename("Perf_Grp" = "performance group") |>
#   select(CNTR_CODE, NUTS_ID, RIS_code, Indicator_ID, Indicator, Value, Perf_Grp)
# 
# writexl::write_xlsx(RIS, "/Users/giocopp/Desktop/LOCALISED-7.1-Paper/Base Data/RIS_2023_select.xlsx")

RIS <- readxl::read_excel("/Users/giocopp/Desktop/LOCALISED-7.1-Paper/Base Data/RIS_2023_select.xlsx")

RIS_Tech <- RIS |> 
  filter(Indicator_ID %in% c("1.2.1", "1.2.2", "2.1.1", "2.2.2", "2.2.3", "3.1.1", "3.1.2", "4.1.1", "4.1.2", "4.2.3")) |> 
  select(-Indicator_ID)

indicator_mapping <- c(
  "1.2.1 International scientific co-publications (Regional)" = "1.2.1_IntlSciPub",
  "1.2.2 Scientific publications among the top 10% most cited (Regional)" = "1.2.2_TopCitedPub",
  "2.1.1 R&D expenditure in the public sector (Regional)" = "2.1.1_PublicRDExp",
  "2.2.2 Non-R&D innovation expenditures (Regional)" = "2.2.2_NonRDInnoExp",
  "2.2.3 Innovation expenditures per person employed (Regional)" = "2.2.3_InnoExpPerEmp",
  "3.1.1 SMEs introducing product innovations (Regional)" = "3.1.1_ProdInnoSMEs",
  "3.1.2 SMEs introducing business process innovations (Regional)" = "3.1.2_ProcInnoSMEs",
  "4.1.1 Employment in knowledge-intensive activities (Regional)" = "4.1.1_KnowledgeEmp",
  "4.1.2 Employment in innovative enterprises (Regional)" = "4.1.2_InnovEmp",
  "4.2.3 Sales of new-to-market and new-to-firm innovations (Regional)" = "4.2.3_SalesNewInno"
)

# Apply the mapping to the dataset
RIS_Tech <- RIS_Tech |> 
  mutate(Indicator = recode(Indicator, !!!indicator_mapping))

RIS_Tech_w <- RIS_Tech |> 
  pivot_wider(
    names_from = Indicator, 
    values_from = Value
  )

RIS_Tech_n <- RIS_Tech_w |> 
  mutate(across(
    where(is.double), # Apply normalization only to double columns
    ~ 0.01 + (.-min(.)) / (max(.) - min(.)) * (0.99 - 0.01) # Normalize to [0.01, 0.99]
  ))

### 
### Eurostat data
### 
### BERD
### 

indicator_df <- restatapi::get_eurostat_data(
  id = "rd_e_berdindr2",
  filters = c("C", "C10-C12", "C13-C15", "C16-C18", "C19", "C20", "C21", "C22", "C23", "C24", "C25", "C26", "C27", "C28", "C29", "C30", "C31", "C32", "C33" ,"BE", "BG", "CZ", "DK", "DE", "EE", "IE", "EL", "ES", "FR", "HR", "IT", "CY", "LV", "LT", "LU", "HU", "MT", "NL", "AT", "PL", "PT", "RO", "SI", "SK", "FI", "SE", "MIO_EUR"), 
  date_filter = c(2023, 2022, 2021, 2020),
  exact_match = T,
  label = F,
  cflags = T,
  keep_flags = T,
)

indicator_df_f <- indicator_df |> 
  dplyr::rename(
    "NUTS_ID" = "geo",
    "Values" = "values",
    "Sector" = "nace_r2",
    "Year" = "time"
  ) |> 
  dplyr::select(NUTS_ID, Sector, Year, Values)


# Impute missing 2023 values with previous years
# Step 1: Ensure the data includes rows for all years in the range (2021â€“2023)
Eurostat_BERD <- indicator_df_f |> 
  dplyr::mutate(Year = as.integer(as.character(Year))) |>  # Convert to integer
  tidyr::complete(NUTS_ID, Sector, Year = 2020:2023)  # Fill missing rows for 2021-2023

# Step 2: Impute missing values for 2023 using previous years
Eurostat_BERD <- Eurostat_BERD |> 
  dplyr::group_by(NUTS_ID, Sector) |> 
  dplyr::mutate(
    Values = case_when(
      # Impute missing 2023 values using 2022 or 2021
      Year == 2023 & is.na(Values) ~ coalesce(
        Values[Year == 2022 & !is.na(Values)][1], 
        Values[Year == 2021 & !is.na(Values)][1],
        Values[Year == 2020 & !is.na(Values)][1]
      ),
      # Impute missing 2022 values using 2021
      Year == 2023 & is.na(Values) ~ Values[Year == 2022 & !is.na(Values)][1],
      Year == 2022 & is.na(Values) ~ Values[Year == 2021 & !is.na(Values)][1],
      Year == 2021 & is.na(Values) ~ Values[Year == 2020 & !is.na(Values)][1],
      # Keep existing values for other cases
      TRUE ~ Values
    )
  ) |> 
  dplyr::ungroup()

# Step 3: Retain only rows for 2023 and drop the Year column
Eurostat_BERD <- Eurostat_BERD |> 
  dplyr::filter(Year == 2023) |> 
  dplyr::select(-Year)

# EU Avg if there are still NAs
sector_eu_avg <- Eurostat_BERD |> 
  dplyr::group_by(Sector) |> 
  dplyr::summarize(
    EU_Avg = mean(Values, na.rm = TRUE),  # Calculate the EU average per sector
    .groups = "drop"
  )

# Step 2: Replace NAs in the `Values` column with the sector EU average
Eurostat_BERD <- Eurostat_BERD |> 
  dplyr::left_join(sector_eu_avg, by = "Sector") |>  # Join to get EU averages
  dplyr::mutate(
    Values = ifelse(is.na(Values), EU_Avg, Values)  # Replace NAs with EU average
  ) |> 
  dplyr::select(-EU_Avg)

### Adapt the Sectors
### Step 1: Create a mapping table for aggregation
sector_mapping <- data.frame(
  Original_Sector = c("C", "C10-C12", "C13-C15", "C16-C18", "C19", "C20", "C21", "C22", "C23", "C24", "C25", "C26", "C27", "C28", "C29", "C30", "C31", "C32", "C33"),
  Aggregated_Sector = c("C", "C10-C12", "C13-C15", "C16-C18", "C19-C22", "C19-C22", "C19-C22", "C19-C22", "C23", "C24", "C25+C28-C30", "C26-C27", "C26-C27", "C25+C28-C30", "C25+C28-C30", "C25+C28-C30", "C31-C32", "C31-C32", "C33")
)

### Step 2: Map the original sectors to the aggregated sectors
Eurostat_BERD <- Eurostat_BERD |>
  left_join(sector_mapping, by = c("Sector" = "Original_Sector"))

### Step 3: Aggregate data by NUTS_ID, Stk_Flow, and Aggregated_Sector
Eurostat_BERD <- Eurostat_BERD |>
  group_by(NUTS_ID, Aggregated_Sector) |>
  summarise(
    Aggregated_Values = sum(Values, na.rm = TRUE),
    .groups = "drop"
  )

### Step 4: Rename columns for clarity
Eurostat_BERD <- Eurostat_BERD |>
  rename(Sector = Aggregated_Sector) |> 
  rename(BERD = Aggregated_Values)

### Normalize min max
normalize_min_max_berd <- function(data, sector_col = "Sector", value_col = "BERD", total_sector = "C") {
  # Identify rows corresponding to the total sector and sub-sectors
  is_total_sector <- data[[sector_col]] == total_sector
  is_subsector <- startsWith(data[[sector_col]], total_sector) & !is_total_sector
  
  # Extract values for total sector and sub-sectors
  total_values <- data[[value_col]][is_total_sector]
  subsector_values <- data[[value_col]][is_subsector]
  
  # Compute min and max for the total sector
  min_C <- min(total_values, na.rm = TRUE)
  max_C <- max(total_values, na.rm = TRUE)
  
  # Compute min and max for all sub-sectors combined
  min_sub <- min(subsector_values, na.rm = TRUE)
  max_sub <- max(subsector_values, na.rm = TRUE)
  
  # Normalize values for the total sector to [0.01, 0.99]
  data[[value_col]][is_total_sector] <- 0.01 + 
    (data[[value_col]][is_total_sector] - min_C) / (max_C - min_C) * (0.99 - 0.01)
  
  # Normalize values for the sub-sectors to [0.01, 0.99]
  data[[value_col]][is_subsector] <- 0.01 + 
    (data[[value_col]][is_subsector] - min_sub) / (max_sub - min_sub) * (0.99 - 0.01)
  
  return(data)
}

Eurostat_BERD_n <- normalize_min_max_berd(Eurostat_BERD, sector_col = "Sector", value_col = "BERD", total_sector = "C")

###
###

base_data <- readxl::read_excel("/Users/giocopp/Desktop/LOCALISED-7.1-Paper/Base Data/base_data_plus.xlsx") |> select(1:3)

Eurostat_BERD <- base_data |> 
  dplyr::left_join(Eurostat_BERD, by = c("CNTR_CODE" = "NUTS_ID")) |> 
  dplyr::select(-NUTS_NAME) |> 
  dplyr::filter(nchar(NUTS_ID) != 2)

Eurostat_BERD_n <- base_data |> 
  dplyr::left_join(Eurostat_BERD_n, by = c("CNTR_CODE" = "NUTS_ID")) |> 
  dplyr::select(-NUTS_NAME) |> 
  dplyr::filter(nchar(NUTS_ID) != 2)

### Merge

expanded_data <- Eurostat_BERD |>
  distinct(NUTS_ID) |>
  crossing(Eurostat_BERD |>
             distinct(Sector))

# Merge the expanded data with the original datasets
Tech_raw <- expanded_data |> 
  left_join(Eurostat_BERD, by = c("NUTS_ID", "Sector")) |>
  left_join(RIS_Tech_w, by = "NUTS_ID")

Tech_raw <- Tech_raw |> 
  select(-CNTR_CODE.x) |> 
  rename(CNTR_CODE = CNTR_CODE.y) |>
  select(-RIS_code) |> 
  select(c(CNTR_CODE, NUTS_ID, everything()))

###
# Merge the expanded data with the original datasets
Tech_Index <- expanded_data |> 
  left_join(Eurostat_BERD_n, by = c("NUTS_ID", "Sector")) |>
  left_join(RIS_Tech_n, by = "NUTS_ID")

Tech_Index <- Tech_Index |> 
  select(-c(RIS_code, CNTR_CODE.y)) |> 
  rename(CNTR_CODE = CNTR_CODE.x)

# Rename columns to remove numbers
colnames(Tech_raw) <- colnames(Tech_raw) %>%
  stringr::str_replace_all("^\\d+_", "")  # Removes leading numbers and underscores

###
colnames(Tech_Index) <- colnames(Tech_Index) %>%
  stringr::str_replace_all("^\\d+\\.\\d+\\.\\d+_", "") %>% # Handle numbers with dots
  stringr::str_replace_all("^\\d+\\.\\d+_", "") %>%        # Handle other numeric patterns
  stringr::str_replace_all("^\\d+_", "")                  # Catch any leftover patterns

### SAVE
# Define output directory
# Create the directory if it doesn't exist
if (!dir.exists("Outputs/Data")) {
  dir.create("Outputs/Data", recursive = TRUE)
}

# Save each dataset to an Excel file
writexl::write_xlsx(Eurostat_BERD, "Outputs/Data/Eurostat_BERD.xlsx")
writexl::write_xlsx(Eurostat_BERD_n, "Outputs/Data/Eurostat_BERD_n.xlsx")
writexl::write_xlsx(RIS_Tech_w, "Outputs/Data/RIS_Tech_w.xlsx")
writexl::write_xlsx(RIS_Tech_n, "Outputs/Data/RIS_Tech_n.xlsx")
writexl::write_xlsx(Tech_raw, "Outputs/Data/Tech_raw.xlsx")
writexl::write_xlsx(Tech_Index, "Outputs/Data/Tech_Index.xlsx")

# Return the paths of the saved files
return(c(
  "Outputs/Data/Eurostat_BERD.xlsx",
  "Outputs/Data/Eurostat_BERD_n.xlsx",
  "Outputs/Data/RIS_Tech_w.xlsx",
  "Outputs/Data/RIS_Tech_n.xlsx",
  "Outputs/Data/Tech_raw.xlsx",
  "Outputs/Data/Tech_Index.xlsx"
))



Tech_Ind